{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters 를 활용한 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부만 할당된 GPU 메모리를 실행하는 동안 필요한만큼 늘릴 수 있도록 설정함\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 결과를 재현하기 위해서 random seed 고정\n",
    "import numpy as np\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 시 불필요한 출력을 끄도록 함 (waning)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 네트워크 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 178us/step - loss: 2.5282 - acc: 0.4980 - val_loss: 1.7209 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 1.4458 - acc: 0.6883 - val_loss: 1.3490 - val_acc: 0.7090\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 1.0968 - acc: 0.7646 - val_loss: 1.1727 - val_acc: 0.7440\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.8713 - acc: 0.8155 - val_loss: 1.0866 - val_acc: 0.7570\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.7050 - acc: 0.8485 - val_loss: 0.9858 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.5677 - acc: 0.8794 - val_loss: 0.9426 - val_acc: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.4592 - acc: 0.9052 - val_loss: 0.9094 - val_acc: 0.8040\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.3701 - acc: 0.9230 - val_loss: 0.9367 - val_acc: 0.7910\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.3034 - acc: 0.9313 - val_loss: 0.8931 - val_acc: 0.8050\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.2540 - acc: 0.9415 - val_loss: 0.9068 - val_acc: 0.8120\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.2183 - acc: 0.9474 - val_loss: 0.9202 - val_acc: 0.8100\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1876 - acc: 0.9511 - val_loss: 0.9084 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.1698 - acc: 0.9525 - val_loss: 0.9333 - val_acc: 0.8080\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.1533 - acc: 0.9558 - val_loss: 0.9653 - val_acc: 0.8060\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1388 - acc: 0.9558 - val_loss: 0.9693 - val_acc: 0.8140\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1315 - acc: 0.9558 - val_loss: 1.0241 - val_acc: 0.8040\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1219 - acc: 0.9579 - val_loss: 1.0240 - val_acc: 0.8000\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1198 - acc: 0.9579 - val_loss: 1.0436 - val_acc: 0.8030\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.1138 - acc: 0.9597 - val_loss: 1.0975 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.1112 - acc: 0.9595 - val_loss: 1.0701 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습 과정 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (과대적합 되기 전까지) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 167us/step - loss: 2.5395 - acc: 0.5226 - val_loss: 1.6735 - val_acc: 0.6570\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 1.3720 - acc: 0.7116 - val_loss: 1.2761 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 1.0138 - acc: 0.7789 - val_loss: 1.1309 - val_acc: 0.7550\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.7976 - acc: 0.8247 - val_loss: 1.0534 - val_acc: 0.7590\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.6393 - acc: 0.8631 - val_loss: 0.9744 - val_acc: 0.7940\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.5110 - acc: 0.8926 - val_loss: 0.9093 - val_acc: 0.8140\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.4104 - acc: 0.9144 - val_loss: 0.8914 - val_acc: 0.8200\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.3342 - acc: 0.9291 - val_loss: 0.8716 - val_acc: 0.8300\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.2774 - acc: 0.9375 - val_loss: 0.9365 - val_acc: 0.8020\n",
      "2246/2246 [==============================] - 0s 134us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 학습된 모델로 새로운 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서부터는 추가적인 내용\n",
    "\n",
    "## sparse_categorical_crossentropy\n",
    "\n",
    "지금까지 해봤던 예시에서는, 개발자가 직접 예측값에 대해 one-hot-encoding 을 시켜주었어야 하는데,\n",
    "\n",
    "loss 옵션에 sparse_categorical_crossentropy 를 주면, 케라스에서 알아서 원핫인코딩을 해줌,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 충분히 큰 층을 두어야 하는 이유?\n",
    "\n",
    "- 우리가 지금 input 에 넣은것은 10000개의 데이터인데, 이 데이터들이 전체를 대변하는 것은 당연히 아님.\n",
    "- 보통은 깔대기 모양으로 (뒤의 층으로 갈수록) 유닛의 갯수를 맞춰주는 것이 일반적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 200us/step - loss: 3.1696 - acc: 0.2433 - val_loss: 2.6142 - val_acc: 0.2740\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 2.0606 - acc: 0.5461 - val_loss: 1.7033 - val_acc: 0.5860\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 1.5012 - acc: 0.6233 - val_loss: 1.5122 - val_acc: 0.6390\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 1.2887 - acc: 0.6907 - val_loss: 1.4120 - val_acc: 0.6780\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 1.1457 - acc: 0.7159 - val_loss: 1.3673 - val_acc: 0.6830\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 1.0403 - acc: 0.7313 - val_loss: 1.3424 - val_acc: 0.6980\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.9587 - acc: 0.7424 - val_loss: 1.3385 - val_acc: 0.7010\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.8893 - acc: 0.7522 - val_loss: 1.3379 - val_acc: 0.7030\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.8265 - acc: 0.7696 - val_loss: 1.3620 - val_acc: 0.7090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.7666 - acc: 0.7890 - val_loss: 1.3755 - val_acc: 0.7070\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 0.7129 - acc: 0.8056 - val_loss: 1.3978 - val_acc: 0.7160\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.6673 - acc: 0.8167 - val_loss: 1.3991 - val_acc: 0.7210\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 157us/step - loss: 0.6235 - acc: 0.8301 - val_loss: 1.4611 - val_acc: 0.7130\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.5862 - acc: 0.8365 - val_loss: 1.4664 - val_acc: 0.7190\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.5524 - acc: 0.8472 - val_loss: 1.5151 - val_acc: 0.7210\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.5217 - acc: 0.8547 - val_loss: 1.5580 - val_acc: 0.7200\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 160us/step - loss: 0.4953 - acc: 0.8641 - val_loss: 1.5783 - val_acc: 0.7250\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 159us/step - loss: 0.4684 - acc: 0.8805 - val_loss: 1.6358 - val_acc: 0.7180\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 157us/step - loss: 0.4446 - acc: 0.8849 - val_loss: 1.6694 - val_acc: 0.7120\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 156us/step - loss: 0.4270 - acc: 0.8908 - val_loss: 1.7331 - val_acc: 0.7160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28881da72b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras2",
   "language": "python",
   "name": "ywkeras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
